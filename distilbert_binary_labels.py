# -*- coding: utf-8 -*-
"""distilbert-binary-labels

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CegjQz64eee6RSi4lTP-DIQ_i-o--Jtz
"""

!pip install transformers

from transformers import DistilBertTokenizer
from transformers import TFDistilBertForSequenceClassification
import tensorflow as tf
import json
from transformers import AutoTokenizer

import pandas as pd

#loads cleaned tweets as a dataframe
df = pd.read_csv('binary_tweets.csv') # Change path to your download location
df.head()

import matplotlib.pyplot as plt

# creating the dataset
data = {'0':520, '1':620}
courses = list(data.keys())
values = list(data.values())

fig = plt.figure(figsize = (6, 5))

# creating the bar plot

c = ['red', 'pink']

#bar plot
plt.bar(courses, values, color =c,
        width = 0.6, alpha = 0.4)

colors = {'Irrelevant':'red', 'Relevant':'pink'}
labels = list(colors.keys())
handles = [plt.Rectangle((0,0),1,1, color=colors[label], alpha = 0.4) for label in labels]
plt.legend(handles, labels)
plt.xlabel("Category")
plt.ylabel("Number of Tweets")
plt.show()

df2 = df.groupby(['labels'])['labels'].count()

df2

import matplotlib.pyplot as plt

# creating the dataset
data = {'0':520, '1':1001}
courses = list(data.keys())
values = list(data.values())

fig = plt.figure(figsize = (6, 5))

# creating the bar plot

c = ['maroon', 'navy']

#bar plot
plt.bar(courses, values, color =c,
        width = 0.6)

colors = {'Irrelevant':'maroon', 'Relevant':'navy'}
labels = list(colors.keys())
handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels]
plt.legend(handles, labels)
plt.xlabel("Category")
plt.ylabel("Number of Tweets")
plt.show()

data_texts = df["text"].to_list() # Features (not-tokenized yet)
data_labels = df["labels"].to_list() # Lables

from sklearn.model_selection import train_test_split

# Split Train and Validation data
train_texts, val_texts, train_labels, val_labels = train_test_split(data_texts, data_labels, test_size=0.20)

# Keep some data for inference (testing)
train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size=0.10)

len(train_labels)

#tokenizer given by distilbert
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

#tokenize train dataset and validation dataset with no truncation or padding
train_encodings = tokenizer(train_texts, truncation=True, padding=True)
val_encodings = tokenizer(val_texts, truncation=True, padding=True)

#transform train and validation datasets into tensor dataset
train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    train_labels
))
val_dataset = tf.data.Dataset.from_tensor_slices((
    dict(val_encodings),
    val_labels
))

#load model with metrics to be used
model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)
optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)
model.compile(optimizer=optimizer, loss=model.hf_compute_loss, metrics=['accuracy'])

#shuffles data and fine tunes model with 4 epochs and batch size of 16
model.fit(train_dataset.shuffle(667).batch(16), epochs=4, batch_size=16,
          validation_data=val_dataset.shuffle(667).batch(16))

#saves model
save_directory = "/saved_models/binary_model" # change this to your preferred location

model.save_pretrained(save_directory)
tokenizer.save_pretrained(save_directory)

# Commented out IPython magic to ensure Python compatibility.
# #get predicted label for the validation tweets and add to array
# %%timeit
# y_pred = []
# for i in range(len(test_texts)):
#   inputs = tokenizer(test_texts[i], return_tensors="tf")
#   logits = model(**inputs).logits
#   prediction_value = int(tf.math.argmax(logits, axis=-1)[0])
# 
#   y_pred.append(prediction_value)

for i in range(len(test_texts)):
  if y_pred[i] != test_labels[i] and test_labels[i]==1:
    print(test_texts[i])
    print()

from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score

#prints metrics for validation dataset
print("Accuracy:",accuracy_score(test_labels, y_pred))
print("F1-score:",f1_score(test_labels, y_pred, average='macro'))
print("Recall:",recall_score(test_labels, y_pred, average='macro'))
print("Precision:",precision_score(test_labels, y_pred, average='macro'))

from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

#plots confusion matrix for each label
cm = confusion_matrix(test_labels, y_pred, labels=[0,1])

cm_display = ConfusionMatrixDisplay(cm, display_labels=[0,1]).plot()

