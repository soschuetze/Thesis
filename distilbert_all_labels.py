# -*- coding: utf-8 -*-
"""distilbert-all-labels

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/153F2ofrCKe9OR5Lcrm9aE4hz1miqyFGY
"""

!pip install transformers

from transformers import DistilBertTokenizer
from transformers import TFDistilBertForSequenceClassification
import tensorflow as tf
import json
from transformers import AutoTokenizer



import pandas as pd

#loads cleaned tweets as a dataframe
df = pd.read_csv('new_labels_no_zeros.csv') # Change path to your download location
df.head()

#plots number of tweets by classes
df2 = df.groupby(['labels'])['labels'].count()
print(df2)

import matplotlib.pyplot as plt

# creating the dataset
data = {'0':311, '1':205, '2':483}
courses = list(data.keys())
values = list(data.values())

fig = plt.figure(figsize = (6, 5))

# creating the bar plot

c = ['royalblue', 'orange','green']

#bar plot
plt.bar(courses, values, color =c,
        width = 0.6)

colors = {'Within the System':'royalblue', 'Disruptive':'orange', 'Spreading Info':'green'}
labels = list(colors.keys())
handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels]
plt.legend(handles, labels)
plt.xlabel("Category")
plt.ylabel("Number of Tweets")
plt.show()

data_texts = df["text"].to_list() # Features (not-tokenized yet)
data_labels = df["labels"].to_list() # Labels

from sklearn.model_selection import train_test_split

# Split Train and Validation data
train_texts, val_texts, train_labels, val_labels = train_test_split(data_texts, data_labels, test_size=0.30)

# Keep some data for inference (testing)
train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size=0.20)

#tokenizer given by distilbert
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

#tokenize train dataset and validation dataset with no truncation or padding
train_encodings = tokenizer(train_texts, truncation=True, padding=True)
val_encodings = tokenizer(val_texts, truncation=True, padding=True)

#transform train and validation datasets into tensor dataset
train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    train_labels
))
val_dataset = tf.data.Dataset.from_tensor_slices((
    dict(val_encodings),
    val_labels
))

#load model with metrics to be used
model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)
optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)
model.compile(optimizer=optimizer, loss=model.hf_compute_loss, metrics=['accuracy'])

#shuffles data and fine tunes model with 4 epochs and batch size of 16
model.fit(train_dataset.shuffle(667).batch(16), epochs=4, batch_size=16,
          validation_data=val_dataset.shuffle(667).batch(16))

#saves model
save_directory = "/saved_models" # change this to your preferred location

model.save_pretrained(save_directory)
tokenizer.save_pretrained(save_directory)

#get predicted label for the validation tweets and add to array
y_pred = []
for i in range(len(test_texts)):
  predict_input = tokenizer.encode(test_texts[i],
                                 truncation=True,
                                 padding=True,
                                 return_tensors="tf")

  output = model(predict_input)[0]
  prediction_value = tf.argmax(output, axis=1).numpy()[0]
  y_pred.append(prediction_value)

len(y_pred)

for i in range(len(test_texts)):
  if y_pred[i] != test_labels[i] and test_labels[i]==2 and y_pred[i]==0:
    print(test_texts[i])
    print()

from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score

#prints metrics for validation dataset
print("Accuracy:",accuracy_score(test_labels, y_pred))
print("F1-score:",f1_score(test_labels, y_pred, average='macro'))
print("Recall:",recall_score(test_labels, y_pred, average='macro'))
print("Precision:",precision_score(test_labels, y_pred, average='macro'))

from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

#plots confusion matrix for each label
cm = confusion_matrix(test_labels, y_pred, labels=[0,1,2])

cm_display = ConfusionMatrixDisplay(cm, display_labels=[0,1,2]).plot()

